# **MAVAE**

In this paper,we propose a Multimodal Attention-based VAE (MAVAE) deep learning framework using cross-modal multihead attention to integrate cancer multiomics data for clinical risk prediction. We evaluated our approach on eight TCGA datasets. We find that (1) MAVAE outperforms traditional machine learning and recent deep learning methods; (2) Multi-modal data yields better classification performance than single-modal data; (3) The multi-head attention mechanism improves the decision-making process; (4) Clinical and genetic data are the most important modal data. 

![](https://github.com/wenwenmin/MAVAE/blob/main/MAVAE.png)https://github.com/wenwenmin/MAVAE/blob/main/MAVAE.png)
